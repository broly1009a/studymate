# StudyMate AI Copilot - ChatGPT Integration Guide

## ðŸ“‹ Overview

StudyMate AI Copilot Ä‘Æ°á»£c tÃ­ch há»£p ChatGPT (GPT-4o-mini) vá»›i cÃ¡c tá»‘i Æ°u Ä‘á»ƒ **giáº£m chi phÃ­ token**:
- **Má»¥c tiÃªu**: 50 users/ngÃ y, ~300-500k VND token/thÃ¡ng
- **MÃ´ hÃ¬nh**: GPT-4o-mini (~$0.15/1M input tokens)
- **Chiáº¿n lÆ°á»£c**: Template responses + Prompt caching + RAG pattern

---

## ðŸš€ Quick Start

### 1. Setup Environment Variables

Táº¡o file `.env.local`:

```env
OPENAI_API_KEY=sk-...your-api-key...
```

Láº¥y API key tá»«: https://platform.openai.com/api-keys

### 2. Install Dependencies

```bash
npm install openai
# Already in package.json
```

### 3. Add AI Chat Widget to Your App

Trong `src/app/layout.tsx` hoáº·c dashboard layout:

```tsx
import { AIChatWidget } from '@/components/ai/ai-chat-widget';

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html>
      <body>
        {children}
        <AIChatWidget position="bottom-right" />
      </body>
    </html>
  );
}
```

---

## ðŸŽ¯ Architecture

### API Endpoint: `POST /api/ai/chat`

**Request:**
```json
{
  "message": "KhÃ³a há»c nÃ o phÃ¹ há»£p cho tÃ´i?",
  "userId": "user_123",
  "sessionId": "session_456"
}
```

**Response:**
```json
{
  "response": "TÃ´i cáº§n láº¥y dá»¯ liá»‡u cá»§a báº¡n tá»« há»‡ thá»‘ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c.",
  "type": "action_required",
  "action": "FETCH_DATA[COURSES]",
  "metadata": {
    "tokensUsed": 0,
    "costEstimate": 0,
    "dataType": "COURSES"
  }
}
```

---

## ðŸ’° Cost Optimization Strategy

### 1. **Template Responses** (0 tokens)

CÃ¡c cÃ¢u há»i phá»• biáº¿n Ä‘Æ°á»£c tráº£ lá»i tá»« templates:
- HÆ°á»›ng dáº«n sá»­ dá»¥ng
- TÃ­nh nÄƒng chÃ­nh
- Máº¹o há»c táº­p
- Váº¥n Ä‘á» ká»¹ thuáº­t

**File**: `src/lib/ai-system-prompt.ts` â†’ `TEMPLATE_RESPONSES`

### 2. **Prompt Caching** (~25% tiáº¿t kiá»‡m)

System prompt Ä‘Æ°á»£c cache trong 5 phÃºt:
```typescript
cache_control: { type: 'ephemeral' }
```

**Æ¯á»›c tÃ­nh**: Tá»« 150 tokens xuá»‘ng 110 tokens/question

### 3. **Data Fetch Action** (Server-side handling)

Khi cáº§n dá»¯ liá»‡u ngÆ°á»i dÃ¹ng, AI tráº£ vá» action thay vÃ¬ hallucinate:

```
INPUT: "KhÃ³a há»c cá»§a tÃ´i lÃ  gÃ¬?"
OUTPUT: "ACTION_REQUIRED: FETCH_DATA[COURSES]"
```

Frontend sáº½ fetch dá»¯ liá»‡u vÃ  trÃ¬nh bÃ y láº¡i, AI khÃ´ng tham gia.

### 4. **Output Token Limiting**

Max 150 tokens/response = tá»‘i Ä‘a ~5 cÃ¢u:
```typescript
max_tokens: 150
```

---

## ðŸ“Š Cost Breakdown

**Giáº£ Ä‘á»‹nh**: 50 users/ngÃ y, 3 questions/user

### Scenario 1: KhÃ´ng tá»‘i Æ°u (ChatGPT thÆ°á»ng)
- 150 questions/ngÃ y
- ~300 tokens/question (avg)
- 45,000 tokens/ngÃ y
- ~45k Ã— 30 = 1.35M tokens/thÃ¡ng
- **Chi phÃ­**: ~6,750 VND/thÃ¡ng âŒ

### Scenario 2: CÃ³ tá»‘i Æ°u (StudyMate)
- 150 questions/ngÃ y
- ~60 questions dÃ¹ng template (40%) â†’ 0 tokens
- ~60 questions dÃ¹ng data fetch (40%) â†’ 0 tokens  
- ~30 questions dÃ¹ng LLM (20%) â†’ 120 tokens (vá»›i cache)
- = 3,600 tokens/ngÃ y
- **Chi phÃ­**: ~432 VND/thÃ¡ng âœ…

**Tiáº¿t kiá»‡m**: ~94% chi phÃ­ token! ðŸ“‰

---

## ðŸ”§ Configuration

### System Prompt

File: `src/lib/ai-system-prompt.ts`

```typescript
export const STUDYMATE_SYSTEM_PROMPT = `
Báº¡n lÃ  StudyMate AI Copilot.
...
`;
```

**Quy táº¯c Ä‘áº·t trong prompt**:
1. âœ… Ngáº¯n gá»n (trÃ¡nh dÃ i dÃ²ng)
2. âœ… RÃµ rÃ ng, Ä‘á»‹nh hÆ°á»›ng tá»«ng bÆ°á»›c
3. âœ… Chá»‰ Ä‘á»‹nh output format (text, khÃ´ng markdown)
4. âœ… NÃªu rÃµ khi cáº§n data fetch

### Keyword Routing

CÃ¡ch phÃ¢n loáº¡i cÃ¢u há»i mÃ  **khÃ´ng cáº§n gá»i LLM**:

```typescript
export const KEYWORD_ROUTING = {
  my_courses: ['khÃ³a há»c cá»§a tÃ´i', 'Ä‘Ã£ Ä‘Äƒng kÃ½', ...],
  study_tips: ['há»c táº­p', 'phÆ°Æ¡ng phÃ¡p', ...],
  // ...
};
```

ThÃªm keywords vÃ o Ä‘á»ƒ tÄƒng coverage template responses.

---

## ðŸŽ® Usage Examples

### Example 1: Template Response (0 tokens)

```
User: "LÃ m sao Ä‘á»ƒ há»c hiá»‡u quáº£?"
AI:   "Há»c hiá»‡u quáº£: Chia thÃ nh pháº§n nhá», há»c Ä‘á»u Ä‘áº·n..."
Cost: 0 VND
```

### Example 2: Data Fetch Action (0 tokens)

```
User: "KhÃ³a há»c cá»§a tÃ´i lÃ  gÃ¬?"
AI:   "ACTION_REQUIRED: FETCH_DATA[COURSES]"
Cost: 0 VND
Frontend: Fetch tá»« /api/profiles, hiá»ƒn thá»‹ danh sÃ¡ch
```

### Example 3: LLM Call (120 tokens, ~360 VND)

```
User: "TÃ´i muá»‘n há»c Python, nhÆ°ng chÆ°a bao giá» láº­p trÃ¬nh..."
AI:   "Báº¡n nÃªn báº¯t Ä‘áº§u vá»›i khÃ³a há»c cÆ¡ báº£n..."
Cost: ~360 VND
```

---

## ðŸ“ˆ Monitoring & Metrics

### Log Token Usage

```typescript
// In response metadata
metadata: {
  tokensUsed: 120,
  costEstimate: 360, // VND
  breakdown: {
    inputTokens: 90,
    outputTokens: 30,
  }
}
```

### Track in Dashboard

ThÃªm endpoint Ä‘á»ƒ theo dÃµi chi phÃ­:

```typescript
// POST /api/ai/metrics
{
  date: "2024-01-15",
  totalUsers: 45,
  totalQuestions: 132,
  templateResponsesUsed: 88, // 67%
  dataFetchActionsIssued: 32, // 24%
  llmCallsUsed: 12,           // 9%
  averageTokensPerQuestion: 15,
  estimatedCostVND: 4500,
}
```

---

## ðŸ”’ Security & Rate Limiting

### Rate Limit (Optional)

```typescript
// Trong /api/ai/chat
const rateLimit = await checkRateLimit(userId);
if (!rateLimit.allowed) {
  return NextResponse.json(
    { error: 'Too many requests' },
    { status: 429 }
  );
}
```

### Input Validation

- Max message length: 200 characters
- Trim whitespace
- Reject empty messages

---

## ðŸ› Troubleshooting

### Error: "API key is invalid"

```bash
# Check .env.local
echo $env:OPENAI_API_KEY
```

### High Token Usage

1. Kiá»ƒm tra `TEMPLATE_RESPONSES` - cÃ³ thiáº¿u keywords khÃ´ng?
2. Review `KEYWORD_ROUTING` - cÃ³ cÃ¢u há»i nÃ o bá»‹ miss?
3. Giáº£m `max_tokens` xuá»‘ng 100
4. ThÃªm DATA_FETCH types Ä‘á»ƒ giáº£m LLM calls

### Cache Not Working?

Prompt caching chá»‰ hoáº¡t Ä‘á»™ng khi:
- Input â‰¥ 1024 tokens (system + user)
- 5 phÃºt liÃªn tá»¥c dÃ¹ng
- Sá»­ dá»¥ng GPT-4o/gpt-4o-mini

---

## ðŸ“ Best Practices

### 1. **Always Use Templates First**

```typescript
// âŒ Sai
await callOpenAI("KhÃ³a há»c nÃ o phÃ¹ há»£p cho tÃ´i?");

// âœ… ÄÃºng
const classification = classifyMessage(userMessage);
if (classification.type === 'template') {
  return TEMPLATE_RESPONSES[classification.templateKey];
}
```

### 2. **Data Fetch â‰  Hallucination**

```typescript
// âŒ Sai: AI tá»± táº¡o dá»¯ liá»‡u
"Báº¡n Ä‘ang há»c 5 khÃ³a há»c: Python, JavaScript..."

// âœ… ÄÃºng: BÃ¡o hiá»‡u fetch data
"ACTION_REQUIRED: FETCH_DATA[COURSES]"
```

### 3. **Batch User Data Requests**

Náº¿u cáº§n láº¥y nhiá»u data, fetch 1 láº§n:

```typescript
// Thay vÃ¬ gá»i N láº§n FETCH_DATA
return "ACTION_REQUIRED: FETCH_DATA[COURSES,SCHEDULE,PROGRESS]";
```

### 4. **Log Everything for Optimization**

```typescript
console.log({
  message: userMessage,
  classification: classification.type,
  tokensUsed: response.usage.total_tokens,
  timestamp: new Date(),
});
```

---

## ðŸŽ“ Next Steps

1. âœ… Setup OPENAI_API_KEY trong `.env.local`
2. âœ… ThÃªm AIChatWidget vÃ o layout
3. âœ… Test cÃ¡c scenarios trong `TEMPLATE_RESPONSES`
4. âœ… Má»Ÿ DevTools, kiá»ƒm tra metadata tá»« /api/ai/chat
5. âœ… Má»Ÿ Platform > Usage trong OpenAI dashboard Ä‘á»ƒ track chi phÃ­

---

## ðŸ“š References

- OpenAI API: https://platform.openai.com/docs/api-reference
- GPT-4o-mini Pricing: https://openai.com/pricing
- Prompt Caching: https://platform.openai.com/docs/guides/prompt-caching
- Rate Limiting: https://platform.openai.com/docs/guides/rate-limits

---

**TÃ¡c giáº£**: StudyMate AI Team  
**PhiÃªn báº£n**: 1.0.0  
**Cáº­p nháº­t**: 2024-12-17
